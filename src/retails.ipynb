{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import requests #--pip install requests\n",
    "#!pip install pycountry\n",
    "#!pip install pyzipcode\n",
    "import pycountry\n",
    "import re\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split # Divisi√≥n del dataset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.lines import Line2D\n",
    "from geopy.geocoders import Photon\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from pyzipcode import ZipCodeDatabase\n",
    "#from uszipcode import SearchEngine, SimpleZipcode, Zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retail Analysis on Large Dataset\n",
    "https://www.kaggle.com/datasets/sahilprajapati143/retail-analysis-large-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail = pd.read_csv('../data/new_retail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9060300"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Segment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "      <th>Total_Purchases</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Type</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Shipping_Method</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Order_Status</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8691788.0</td>\n",
       "      <td>37249.0</td>\n",
       "      <td>Michelle Harrington</td>\n",
       "      <td>Ebony39@gmail.com</td>\n",
       "      <td>1.414787e+09</td>\n",
       "      <td>3959 Amanda Burgs</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>77985.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Regular</td>\n",
       "      <td>9/18/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>September</td>\n",
       "      <td>22:03:55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.028757</td>\n",
       "      <td>324.086270</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Same-Day</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cycling shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174773.0</td>\n",
       "      <td>69749.0</td>\n",
       "      <td>Kelsey Hill</td>\n",
       "      <td>Mark36@gmail.com</td>\n",
       "      <td>6.852900e+09</td>\n",
       "      <td>82072 Dawn Centers</td>\n",
       "      <td>Nottingham</td>\n",
       "      <td>England</td>\n",
       "      <td>99071.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Low</td>\n",
       "      <td>Premium</td>\n",
       "      <td>12/31/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>December</td>\n",
       "      <td>8:42:04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>403.353907</td>\n",
       "      <td>806.707815</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Processing</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Lenovo Tab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6679610.0</td>\n",
       "      <td>30192.0</td>\n",
       "      <td>Scott Jensen</td>\n",
       "      <td>Shane85@gmail.com</td>\n",
       "      <td>8.362160e+09</td>\n",
       "      <td>4133 Young Canyon</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>75929.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4/26/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>April</td>\n",
       "      <td>4:06:29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>354.477600</td>\n",
       "      <td>1063.432799</td>\n",
       "      <td>Books</td>\n",
       "      <td>Penguin Books</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Average</td>\n",
       "      <td>Same-Day</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Processing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sports equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7232460.0</td>\n",
       "      <td>62101.0</td>\n",
       "      <td>Joseph Miller</td>\n",
       "      <td>Mary34@gmail.com</td>\n",
       "      <td>2.776752e+09</td>\n",
       "      <td>8148 Thomas Creek Suite 100</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>88420.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>Premium</td>\n",
       "      <td>5/8/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>May</td>\n",
       "      <td>14:55:17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>352.407717</td>\n",
       "      <td>2466.854021</td>\n",
       "      <td>Home Decor</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Tools</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Standard</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Processing</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Utility knife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4983775.0</td>\n",
       "      <td>27901.0</td>\n",
       "      <td>Debra Coleman</td>\n",
       "      <td>Charles30@gmail.com</td>\n",
       "      <td>9.098268e+09</td>\n",
       "      <td>5813 Lori Ports Suite 269</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>England</td>\n",
       "      <td>48704.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Premium</td>\n",
       "      <td>1/10/2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>January</td>\n",
       "      <td>16:54:07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.276524</td>\n",
       "      <td>248.553049</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Nestle</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Chocolate cookies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction_ID  Customer_ID                 Name                Email  \\\n",
       "0       8691788.0      37249.0  Michelle Harrington    Ebony39@gmail.com   \n",
       "1       2174773.0      69749.0          Kelsey Hill     Mark36@gmail.com   \n",
       "2       6679610.0      30192.0         Scott Jensen    Shane85@gmail.com   \n",
       "3       7232460.0      62101.0        Joseph Miller     Mary34@gmail.com   \n",
       "4       4983775.0      27901.0        Debra Coleman  Charles30@gmail.com   \n",
       "\n",
       "          Phone                      Address        City            State  \\\n",
       "0  1.414787e+09            3959 Amanda Burgs    Dortmund           Berlin   \n",
       "1  6.852900e+09           82072 Dawn Centers  Nottingham          England   \n",
       "2  8.362160e+09            4133 Young Canyon     Geelong  New South Wales   \n",
       "3  2.776752e+09  8148 Thomas Creek Suite 100    Edmonton          Ontario   \n",
       "4  9.098268e+09    5813 Lori Ports Suite 269     Bristol          England   \n",
       "\n",
       "   Zipcode    Country   Age  Gender Income Customer_Segment        Date  \\\n",
       "0  77985.0    Germany  21.0    Male    Low          Regular   9/18/2023   \n",
       "1  99071.0         UK  19.0  Female    Low          Premium  12/31/2023   \n",
       "2  75929.0  Australia  48.0    Male    Low          Regular   4/26/2023   \n",
       "3  88420.0     Canada  56.0    Male   High          Premium    5/8/2023   \n",
       "4  48704.0         UK  22.0    Male    Low          Premium   1/10/2024   \n",
       "\n",
       "     Year      Month      Time  Total_Purchases      Amount  Total_Amount  \\\n",
       "0  2023.0  September  22:03:55              3.0  108.028757    324.086270   \n",
       "1  2023.0   December   8:42:04              2.0  403.353907    806.707815   \n",
       "2  2023.0      April   4:06:29              3.0  354.477600   1063.432799   \n",
       "3  2023.0        May  14:55:17              7.0  352.407717   2466.854021   \n",
       "4  2024.0    January  16:54:07              2.0  124.276524    248.553049   \n",
       "\n",
       "  Product_Category  Product_Brand Product_Type   Feedback Shipping_Method  \\\n",
       "0         Clothing           Nike       Shorts  Excellent        Same-Day   \n",
       "1      Electronics        Samsung       Tablet  Excellent        Standard   \n",
       "2            Books  Penguin Books   Children's    Average        Same-Day   \n",
       "3       Home Decor     Home Depot        Tools  Excellent        Standard   \n",
       "4          Grocery         Nestle    Chocolate        Bad        Standard   \n",
       "\n",
       "  Payment_Method Order_Status  Ratings           products  \n",
       "0     Debit Card      Shipped      5.0     Cycling shorts  \n",
       "1    Credit Card   Processing      4.0         Lenovo Tab  \n",
       "2    Credit Card   Processing      2.0   Sports equipment  \n",
       "3         PayPal   Processing      4.0      Utility knife  \n",
       "4           Cash      Shipped      1.0  Chocolate cookies  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy=df_Retail.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Estudio univariable. Completitud, correctitud y consistencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transaction_ID es el numero unico de transaccion, no deberian de haber repetidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Segment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "      <th>Total_Purchases</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Type</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Shipping_Method</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Order_Status</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8691788.0</td>\n",
       "      <td>37249.0</td>\n",
       "      <td>Michelle Harrington</td>\n",
       "      <td>Ebony39@gmail.com</td>\n",
       "      <td>1.414787e+09</td>\n",
       "      <td>3959 Amanda Burgs</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>77985.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Regular</td>\n",
       "      <td>9/18/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>September</td>\n",
       "      <td>22:03:55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.028757</td>\n",
       "      <td>324.086270</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Same-Day</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cycling shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8973612.0</td>\n",
       "      <td>65701.0</td>\n",
       "      <td>Christopher Lopez</td>\n",
       "      <td>Derrick51@gmail.com</td>\n",
       "      <td>9.286274e+09</td>\n",
       "      <td>57136 Martha Common Apt. 654</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>England</td>\n",
       "      <td>11531.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Regular</td>\n",
       "      <td>5/22/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>May</td>\n",
       "      <td>11:24:20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>344.679185</td>\n",
       "      <td>2412.754296</td>\n",
       "      <td>Home Decor</td>\n",
       "      <td>IKEA</td>\n",
       "      <td>Decorations</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Same-Day</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Processing</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Curtains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3902930.0</td>\n",
       "      <td>77572.0</td>\n",
       "      <td>Jose Spencer</td>\n",
       "      <td>Amber67@gmail.com</td>\n",
       "      <td>8.282195e+09</td>\n",
       "      <td>02936 Roy Village</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>England</td>\n",
       "      <td>98771.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>Regular</td>\n",
       "      <td>10/6/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>October</td>\n",
       "      <td>4:59:02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>334.165698</td>\n",
       "      <td>2004.994190</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Same-Day</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Microsoft Surface Laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>9534452.0</td>\n",
       "      <td>20500.0</td>\n",
       "      <td>Matthew Hicks</td>\n",
       "      <td>Kara43@gmail.com</td>\n",
       "      <td>1.568422e+09</td>\n",
       "      <td>51720 Rachael Spurs Suite 283</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>England</td>\n",
       "      <td>94447.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Regular</td>\n",
       "      <td>6/6/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>June</td>\n",
       "      <td>8:43:39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>201.953735</td>\n",
       "      <td>807.814939</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Zara</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Average</td>\n",
       "      <td>Standard</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Processing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Maxi dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1874788.0</td>\n",
       "      <td>74649.0</td>\n",
       "      <td>Courtney Perry</td>\n",
       "      <td>Tina32@gmail.com</td>\n",
       "      <td>7.402422e+09</td>\n",
       "      <td>571 Samuel Wall Apt. 895</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>England</td>\n",
       "      <td>24895.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4/19/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>April</td>\n",
       "      <td>22:26:07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>289.116783</td>\n",
       "      <td>1445.583914</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Nestle</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>Average</td>\n",
       "      <td>Express</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Chocolate-covered fruits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Transaction_ID  Customer_ID                 Name                Email  \\\n",
       "0        8691788.0      37249.0  Michelle Harrington    Ebony39@gmail.com   \n",
       "32       8973612.0      65701.0    Christopher Lopez  Derrick51@gmail.com   \n",
       "42       3902930.0      77572.0         Jose Spencer    Amber67@gmail.com   \n",
       "72       9534452.0      20500.0        Matthew Hicks     Kara43@gmail.com   \n",
       "93       1874788.0      74649.0       Courtney Perry     Tina32@gmail.com   \n",
       "\n",
       "           Phone                        Address        City    State  Zipcode  \\\n",
       "0   1.414787e+09              3959 Amanda Burgs    Dortmund   Berlin  77985.0   \n",
       "32  9.286274e+09   57136 Martha Common Apt. 654  Portsmouth  England  11531.0   \n",
       "42  8.282195e+09              02936 Roy Village  Portsmouth  England  98771.0   \n",
       "72  1.568422e+09  51720 Rachael Spurs Suite 283  Portsmouth  England  94447.0   \n",
       "93  7.402422e+09       571 Samuel Wall Apt. 895  Portsmouth  England  24895.0   \n",
       "\n",
       "    Country   Age  Gender  Income Customer_Segment       Date    Year  \\\n",
       "0   Germany  21.0    Male     Low          Regular  9/18/2023  2023.0   \n",
       "32       UK  66.0    Male  Medium          Regular  5/22/2023  2023.0   \n",
       "42       UK  68.0  Female    High          Regular  10/6/2023  2023.0   \n",
       "72       UK  61.0  Female  Medium          Regular   6/6/2023  2023.0   \n",
       "93       UK  18.0    Male    High          Regular  4/19/2023  2023.0   \n",
       "\n",
       "        Month      Time  Total_Purchases      Amount  Total_Amount  \\\n",
       "0   September  22:03:55              3.0  108.028757    324.086270   \n",
       "32        May  11:24:20              7.0  344.679185   2412.754296   \n",
       "42    October   4:59:02              6.0  334.165698   2004.994190   \n",
       "72       June   8:43:39              4.0  201.953735    807.814939   \n",
       "93      April  22:26:07              5.0  289.116783   1445.583914   \n",
       "\n",
       "   Product_Category Product_Brand Product_Type   Feedback Shipping_Method  \\\n",
       "0          Clothing          Nike       Shorts  Excellent        Same-Day   \n",
       "32       Home Decor          IKEA  Decorations  Excellent        Same-Day   \n",
       "42      Electronics         Apple       Laptop        Bad        Same-Day   \n",
       "72         Clothing          Zara        Dress    Average        Standard   \n",
       "93          Grocery        Nestle    Chocolate    Average         Express   \n",
       "\n",
       "   Payment_Method Order_Status  Ratings                  products  \n",
       "0      Debit Card      Shipped      5.0            Cycling shorts  \n",
       "32     Debit Card   Processing      5.0                  Curtains  \n",
       "42     Debit Card      Shipped      1.0  Microsoft Surface Laptop  \n",
       "72         PayPal   Processing      2.0                Maxi dress  \n",
       "93     Debit Card    Delivered      2.0  Chocolate-covered fruits  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrar valores que se repiten en 'Transaction_ID'\n",
    "duplicate_values_copy = df_Retail_copy[df_Retail_copy.duplicated(subset=['Transaction_ID'], keep=False)]\n",
    "\n",
    "# Guardar duplicate_values como DataFrame\n",
    "duplicate_values_copy = pd.DataFrame(duplicate_values_copy)\n",
    "duplicate_values_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Segment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "      <th>Total_Purchases</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Type</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Shipping_Method</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Order_Status</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8691788.0</td>\n",
       "      <td>37249.0</td>\n",
       "      <td>Michelle Harrington</td>\n",
       "      <td>Ebony39@gmail.com</td>\n",
       "      <td>1.414787e+09</td>\n",
       "      <td>3959 Amanda Burgs</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>77985.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Regular</td>\n",
       "      <td>9/18/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>September</td>\n",
       "      <td>22:03:55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.028757</td>\n",
       "      <td>324.086270</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Same-Day</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cycling shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112551</th>\n",
       "      <td>8691788.0</td>\n",
       "      <td>57392.0</td>\n",
       "      <td>Jacqueline Collins</td>\n",
       "      <td>Krystal93@gmail.com</td>\n",
       "      <td>5.575568e+09</td>\n",
       "      <td>32467 Lopez Falls Suite 272</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>88811.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Medium</td>\n",
       "      <td>New</td>\n",
       "      <td>12/29/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>December</td>\n",
       "      <td>20:43:59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>147.379781</td>\n",
       "      <td>294.759562</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Sony</td>\n",
       "      <td>Television</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Processing</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LED TV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Transaction_ID  Customer_ID                 Name                Email  \\\n",
       "0            8691788.0      37249.0  Michelle Harrington    Ebony39@gmail.com   \n",
       "112551       8691788.0      57392.0   Jacqueline Collins  Krystal93@gmail.com   \n",
       "\n",
       "               Phone                      Address      City    State  Zipcode  \\\n",
       "0       1.414787e+09            3959 Amanda Burgs  Dortmund   Berlin  77985.0   \n",
       "112551  5.575568e+09  32467 Lopez Falls Suite 272    Ottawa  Ontario  88811.0   \n",
       "\n",
       "        Country   Age Gender  Income Customer_Segment        Date    Year  \\\n",
       "0       Germany  21.0   Male     Low          Regular   9/18/2023  2023.0   \n",
       "112551   Canada  46.0   Male  Medium              New  12/29/2023  2023.0   \n",
       "\n",
       "            Month      Time  Total_Purchases      Amount  Total_Amount  \\\n",
       "0       September  22:03:55              3.0  108.028757    324.086270   \n",
       "112551   December  20:43:59              2.0  147.379781    294.759562   \n",
       "\n",
       "       Product_Category Product_Brand Product_Type   Feedback Shipping_Method  \\\n",
       "0              Clothing          Nike       Shorts  Excellent        Same-Day   \n",
       "112551      Electronics          Sony   Television  Excellent        Standard   \n",
       "\n",
       "       Payment_Method Order_Status  Ratings        products  \n",
       "0          Debit Card      Shipped      5.0  Cycling shorts  \n",
       "112551           Cash   Processing      4.0          LED TV  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_transaction = df_Retail_copy[df_Retail_copy['Transaction_ID'] == 8691788]\n",
    "df_filtered_transaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este resultado es inconsistente, muestra para una misma trasaccion distintos customer_id. Procedo a eliminar duplicados de Transaction_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\n",
    "    'Customer_ID', 'Address', 'City', 'State', 'Zipcode', 'Country', 'Age', 'Gender',\n",
    "    'Income', 'Customer_Segment', 'Date', 'Month', 'Time', 'Total_Purchases',\n",
    "    'Amount', 'Total_Amount', 'Shipping_Method', 'Payment_Method', 'Order_Status', 'Feedback'\n",
    "]\n",
    "\n",
    "# Encontrar Transaction_IDs consistentes para cada columna\n",
    "consistent_transaction_ids = set(df_Retail_copy['Transaction_ID'])  # Inicialmente todos los IDs son v√°lidos\n",
    "for column in columns_to_check:\n",
    "    # Agrupar por Transaction_ID y verificar cu√°ntos valores √∫nicos hay\n",
    "    consistency = df_Retail_copy.groupby('Transaction_ID')[column].nunique()\n",
    "    \n",
    "    # Identificar Transaction_ID donde el valor es consistente (solo un valor √∫nico de la columna)\n",
    "    consistent_ids = consistency[consistency == 1].index\n",
    "    \n",
    "    # Intersecci√≥n con IDs v√°lidos actuales\n",
    "    consistent_transaction_ids &= set(consistent_ids)\n",
    "\n",
    "# Filtrar el DataFrame original para mantener solo los Transaction_IDs con valores consistentes en todas las columnas\n",
    "df_Retail_copy = df_Retail_copy[df_Retail_copy['Transaction_ID'].isin(consistent_transaction_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Customer_ID es el identificador del cliente. Se observa que para un mismo identificador de cliente, el nombre, la direccion, y los datos de la persona son distintos en las transacciones realizadas por el cliente. Esto puede ser una inconsistencia de datos o compras realizadas por familiares, amigos de la persona o robo de cuenta. Como no es posible definir cual es la situacion, continuare estudiando las otras variables y retomare luego esta inconsistencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique=df_Retail_copy.copy()\n",
    "df_Retail_copy_unique['Customer_ID'].value_counts().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el comprador que compro mas veces lo hizo 13 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_unique_copy=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Segment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "      <th>Total_Purchases</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Type</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Shipping_Method</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Order_Status</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>5056596.0</td>\n",
       "      <td>10037.0</td>\n",
       "      <td>Robert Wilson</td>\n",
       "      <td>James32@gmail.com</td>\n",
       "      <td>1.226992e+09</td>\n",
       "      <td>33461 Sarah Forges Suite 845</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>England</td>\n",
       "      <td>20966.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Regular</td>\n",
       "      <td>10/3/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>October</td>\n",
       "      <td>11:16:40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.308952</td>\n",
       "      <td>196.617904</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Pepsi</td>\n",
       "      <td>Soft Drink</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Same-Day</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lemon-lime soda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188313</th>\n",
       "      <td>6849125.0</td>\n",
       "      <td>10037.0</td>\n",
       "      <td>Cassandra Villanueva</td>\n",
       "      <td>Meagan47@gmail.com</td>\n",
       "      <td>6.429721e+09</td>\n",
       "      <td>02641 Stewart Underpass</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>38930.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Low</td>\n",
       "      <td>New</td>\n",
       "      <td>4/8/2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>April</td>\n",
       "      <td>1:33:29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.369356</td>\n",
       "      <td>907.108068</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Express</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1.0</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Transaction_ID  Customer_ID                  Name               Email  \\\n",
       "8531         5056596.0      10037.0         Robert Wilson   James32@gmail.com   \n",
       "188313       6849125.0      10037.0  Cassandra Villanueva  Meagan47@gmail.com   \n",
       "\n",
       "               Phone                       Address        City  \\\n",
       "8531    1.226992e+09  33461 Sarah Forges Suite 845  Portsmouth   \n",
       "188313  6.429721e+09       02641 Stewart Underpass    Adelaide   \n",
       "\n",
       "                  State  Zipcode    Country   Age  Gender  Income  \\\n",
       "8531            England  20966.0         UK  19.0    Male  Medium   \n",
       "188313  New South Wales  38930.0  Australia  44.0  Female     Low   \n",
       "\n",
       "       Customer_Segment       Date    Year    Month      Time  \\\n",
       "8531            Regular  10/3/2023  2023.0  October  11:16:40   \n",
       "188313              New   4/8/2023  2023.0    April   1:33:29   \n",
       "\n",
       "        Total_Purchases      Amount  Total_Amount Product_Category  \\\n",
       "8531                2.0   98.308952    196.617904          Grocery   \n",
       "188313              3.0  302.369356    907.108068      Electronics   \n",
       "\n",
       "       Product_Brand Product_Type Feedback Shipping_Method Payment_Method  \\\n",
       "8531           Pepsi   Soft Drink      Bad        Same-Day           Cash   \n",
       "188313         Apple       Tablet      Bad         Express     Debit Card   \n",
       "\n",
       "       Order_Status  Ratings         products  \n",
       "8531      Delivered      1.0  Lemon-lime soda  \n",
       "188313    Delivered      1.0             iPad  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_filtered2 = df_Retail_unique_copy[df_Retail_unique_copy['Customer_ID'] == 10037]\n",
    "df_filtered2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name es el nombre del cliente, a efectos de corroborar el problema mencionado anteriormente, voy a dejar esta variable, pero la terminare eliminando cuando pase a la etapa de evaluacion estadistica ya que no tiene valor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- City es la ciudad donde el cliente vive\n",
    "Corroborar que la ciudad no tenga caracteres raros y que para una misma ciudad este escrito de forma diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nottingham', 'Geelong', 'Edmonton', 'Bristol', 'Brisbane',\n",
       "       'Kitchener', 'Munich', 'Wollongong', 'Cologne', 'Portsmouth',\n",
       "       'San Jose', 'Hamilton', 'Manchester', 'Cardiff', 'Glasgow', 'Hull',\n",
       "       'Cleveland', 'Southampton', 'Leipzig', 'Cairns', 'London',\n",
       "       'Bielefeld', 'D√ºsseldorf', 'Philadelphia', 'Halifax', 'Montreal',\n",
       "       'Dortmund', 'Mackay', 'Quebec City', 'Barrie', 'Adelaide', 'Leeds',\n",
       "       'Plymouth', 'Perth', 'Sheffield', 'Frankfurt', 'Toronto',\n",
       "       'Kelowna', 'Birmingham', 'Ottawa', 'Liverpool', \"St. John's\",\n",
       "       'Hobart', 'Atlanta', 'New Orleans', 'Wichita', 'Albury-Wodonga',\n",
       "       'Winnipeg', 'Vancouver', 'Hamburg', 'Windsor', 'Calgary',\n",
       "       'Newcastle upon Tyne', 'Townsville', 'Oshawa', 'Houston', 'Berlin',\n",
       "       'Seattle', 'Charlotte', 'New York', 'Milwaukee', 'Edinburgh',\n",
       "       'Launceston', 'Bochum', 'M√ºnster', 'Bonn', 'Columbus', 'Melbourne',\n",
       "       'Leicester', 'Fort Worth', 'Toowoomba', 'Victoria', 'Oxford',\n",
       "       'Saskatoon', 'Memphis', 'Regina', 'Canberra', 'Hanover',\n",
       "       'Long Beach', 'San Francisco', 'Nuremberg', 'Minneapolis',\n",
       "       'Colorado Springs', 'Duisburg', 'Denver', 'Bendigo', 'Bremen',\n",
       "       'Boston', 'Tucson', 'Tulsa', 'Portland', 'Kansas City', 'Brighton',\n",
       "       'Essen', 'Darwin', 'Belfast', 'Sydney', 'Baltimore',\n",
       "       'Virginia Beach', 'Arlington', 'Louisville', 'Mesa', 'Las Vegas',\n",
       "       'Dallas', 'Washington', 'Gold Coast', 'Miami', 'Newcastle',\n",
       "       'San Antonio', 'Fresno', 'Phoenix', 'Austin', 'Stuttgart',\n",
       "       'Chicago', 'Wuppertal', 'Nashville', 'Jacksonville', 'Ballarat',\n",
       "       'Omaha', 'Oklahoma City', 'San Diego', 'Sacramento', 'Dresden',\n",
       "       'Raleigh', 'Oakland', 'Indianapolis', 'Detroit', 'Los Angeles',\n",
       "       'El Paso', nan, 'Albuquerque'], dtype=object)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'Australia', 'Canada', 'Germany', 'USA', nan], dtype=object)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               City    Country\n",
      "1        Nottingham         UK\n",
      "2           Geelong  Australia\n",
      "3          Edmonton     Canada\n",
      "4           Bristol         UK\n",
      "5          Brisbane  Australia\n",
      "...             ...        ...\n",
      "30592  Indianapolis        USA\n",
      "30626       Detroit        USA\n",
      "30635   Los Angeles        USA\n",
      "30684       El Paso        USA\n",
      "30981   Albuquerque        USA\n",
      "\n",
      "[131 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Crear un dataframe con combinaciones √∫nicas de ciudad y pa√≠s\n",
    "unique_cities = df_Retail_copy_unique[['City', 'Country']].drop_duplicates()\n",
    "unique_cities = unique_cities.dropna()\n",
    "print(unique_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariana\\AppData\\Local\\Temp\\ipykernel_22464\\2480248971.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Retail_copy_unique['Country'] =df_Retail_copy_unique['Country'].replace('USA','United States')\n",
      "C:\\Users\\mariana\\AppData\\Local\\Temp\\ipykernel_22464\\2480248971.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Retail_copy_unique['Country'] =df_Retail_copy_unique['Country'].replace('UK','United Kingdom')\n"
     ]
    }
   ],
   "source": [
    "df_Retail_copy_unique['Country'] =df_Retail_copy_unique['Country'].replace('USA','United States')\n",
    "df_Retail_copy_unique['Country'] =df_Retail_copy_unique['Country'].replace('UK','United Kingdom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_validate_country=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna(subset=['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna(subset=['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_countries=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_country(country_name):\n",
    "    try:\n",
    "        # Validate by country name\n",
    "       \n",
    "        country = pycountry.countries.lookup(country_name)\n",
    "        \n",
    "        if(country_name==country.name):\n",
    "           # print(country.name)\n",
    "           pass\n",
    "        else:\n",
    "            print(\"No encontrado\")\n",
    "        return country.name\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "df_Retail_validate_country['pais_valido'] = df_Retail_validate_country.apply(lambda row: validate_country(row['Country']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas los paises son correctos\n"
     ]
    }
   ],
   "source": [
    "# Filtra las filas con resultados incorrectos en la validaci√≥n\n",
    "df_paises_incorrectos = df_Retail_validate_country[df_Retail_validate_country['pais_valido'] == False]\n",
    "if(df_paises_incorrectos.empty):\n",
    "    print(\"Todas los paises son correctos\")\n",
    "else:\n",
    "    print(df_paises_incorrectos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United Kingdom', 'Australia', 'Canada', 'Germany',\n",
       "       'United States', None], dtype=object)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_validate_country['pais_valido'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- State es el estado donde el cliente vive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['England', 'New South Wales', 'Ontario', 'Berlin', 'Virginia',\n",
       "       'Nevada', 'Colorado', 'Arkansas', 'Texas', 'Oklahoma',\n",
       "       'Connecticut', 'Mississippi', nan, 'Wisconsin', 'Oregon',\n",
       "       'Michigan', 'Alaska', 'New Jersey', 'Wyoming', 'Maine', 'Idaho',\n",
       "       'Alabama', 'New Hampshire', 'Minnesota', 'Delaware',\n",
       "       'South Carolina', 'Nebraska', 'New Mexico', 'Arizona', 'Iowa',\n",
       "       'Illinois', 'Ohio', 'Georgia', 'New York', 'Pennsylvania',\n",
       "       'Massachusetts', 'Rhode Island', 'Montana', 'West Virginia',\n",
       "       'Louisiana', 'Indiana', 'Kansas', 'Kentucky', 'Washington',\n",
       "       'South Dakota', 'California', 'Missouri', 'Utah', 'Hawaii',\n",
       "       'North Carolina', 'Tennessee', 'Maryland', 'Vermont',\n",
       "       'North Dakota', 'Florida'], dtype=object)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna(subset=['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['England', 'New South Wales', 'Ontario', 'Berlin', 'Virginia',\n",
       "       'Nevada', 'Colorado', 'Arkansas', 'Texas', 'Oklahoma',\n",
       "       'Connecticut', 'Mississippi', 'Wisconsin', 'Oregon', 'Michigan',\n",
       "       'Alaska', 'New Jersey', 'Wyoming', 'Maine', 'Idaho', 'Alabama',\n",
       "       'New Hampshire', 'Minnesota', 'Delaware', 'South Carolina',\n",
       "       'Nebraska', 'New Mexico', 'Arizona', 'Iowa', 'Illinois', 'Ohio',\n",
       "       'Georgia', 'New York', 'Pennsylvania', 'Massachusetts',\n",
       "       'Rhode Island', 'Montana', 'West Virginia', 'Louisiana', 'Indiana',\n",
       "       'Kansas', 'Kentucky', 'Washington', 'South Dakota', 'California',\n",
       "       'Missouri', 'Utah', 'Hawaii', 'North Carolina', 'Tennessee',\n",
       "       'Maryland', 'Vermont', 'North Dakota', 'Florida'], dtype=object)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique['State'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino la columna State porque solo esta completa para USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nottingham', 'Geelong', 'Edmonton', 'Bristol', 'Brisbane',\n",
       "       'Kitchener', 'Munich', 'Wollongong', 'Cologne', 'Portsmouth',\n",
       "       'San Jose', 'Hamilton', 'Manchester', 'Cardiff', 'Glasgow', 'Hull',\n",
       "       'Cleveland', 'Southampton', 'Leipzig', 'Cairns', 'London',\n",
       "       'Bielefeld', 'D√ºsseldorf', 'Philadelphia', 'Halifax', 'Montreal',\n",
       "       'Dortmund', 'Mackay', 'Quebec City', 'Barrie', 'Adelaide', 'Leeds',\n",
       "       'Plymouth', 'Perth', 'Sheffield', 'Frankfurt', 'Toronto',\n",
       "       'Kelowna', 'Birmingham', 'Ottawa', 'Liverpool', \"St. John's\",\n",
       "       'Hobart', 'Atlanta', 'New Orleans', 'Wichita', 'Albury-Wodonga',\n",
       "       'Winnipeg', 'Vancouver', 'Hamburg', 'Windsor', 'Calgary',\n",
       "       'Newcastle upon Tyne', 'Townsville', 'Oshawa', 'Houston',\n",
       "       'Seattle', 'Charlotte', 'New York', 'Milwaukee', 'Edinburgh',\n",
       "       'Launceston', 'Bochum', 'M√ºnster', 'Bonn', 'Columbus', 'Melbourne',\n",
       "       'Leicester', 'Fort Worth', 'Toowoomba', 'Victoria', 'Oxford',\n",
       "       'Saskatoon', 'Memphis', 'Regina', 'Canberra', 'Hanover',\n",
       "       'Long Beach', 'San Francisco', 'Nuremberg', 'Minneapolis',\n",
       "       'Colorado Springs', 'Duisburg', 'Denver', 'Bendigo', 'Bremen',\n",
       "       'Boston', 'Tucson', 'Tulsa', 'Portland', 'Kansas City', 'Brighton',\n",
       "       'Essen', 'Berlin', 'Darwin', 'Belfast', 'Sydney', 'Baltimore',\n",
       "       'Virginia Beach', 'Arlington', 'Louisville', 'Mesa', 'Las Vegas',\n",
       "       'Dallas', 'Washington', 'Gold Coast', 'Miami', 'Newcastle',\n",
       "       'San Antonio', 'Fresno', 'Phoenix', 'Austin', 'Stuttgart',\n",
       "       'Chicago', 'Wuppertal', 'Nashville', 'Jacksonville', 'Ballarat',\n",
       "       'Omaha', 'Oklahoma City', 'San Diego', 'Sacramento', 'Dresden',\n",
       "       'Raleigh', 'Oakland', 'Indianapolis', 'Detroit', 'Los Angeles',\n",
       "       'El Paso', nan, 'Albuquerque'], dtype=object)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna(subset=['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nottingham', 'Geelong', 'Edmonton', 'Bristol', 'Brisbane',\n",
       "       'Kitchener', 'Munich', 'Wollongong', 'Cologne', 'Portsmouth',\n",
       "       'San Jose', 'Hamilton', 'Manchester', 'Cardiff', 'Glasgow', 'Hull',\n",
       "       'Cleveland', 'Southampton', 'Leipzig', 'Cairns', 'London',\n",
       "       'Bielefeld', 'D√ºsseldorf', 'Philadelphia', 'Halifax', 'Montreal',\n",
       "       'Dortmund', 'Mackay', 'Quebec City', 'Barrie', 'Adelaide', 'Leeds',\n",
       "       'Plymouth', 'Perth', 'Sheffield', 'Frankfurt', 'Toronto',\n",
       "       'Kelowna', 'Birmingham', 'Ottawa', 'Liverpool', \"St. John's\",\n",
       "       'Hobart', 'Atlanta', 'New Orleans', 'Wichita', 'Albury-Wodonga',\n",
       "       'Winnipeg', 'Vancouver', 'Hamburg', 'Windsor', 'Calgary',\n",
       "       'Newcastle upon Tyne', 'Townsville', 'Oshawa', 'Houston',\n",
       "       'Seattle', 'Charlotte', 'New York', 'Milwaukee', 'Edinburgh',\n",
       "       'Launceston', 'Bochum', 'M√ºnster', 'Bonn', 'Columbus', 'Melbourne',\n",
       "       'Leicester', 'Fort Worth', 'Toowoomba', 'Victoria', 'Oxford',\n",
       "       'Saskatoon', 'Memphis', 'Regina', 'Canberra', 'Hanover',\n",
       "       'Long Beach', 'San Francisco', 'Nuremberg', 'Minneapolis',\n",
       "       'Colorado Springs', 'Duisburg', 'Denver', 'Bendigo', 'Bremen',\n",
       "       'Boston', 'Tucson', 'Tulsa', 'Portland', 'Kansas City', 'Brighton',\n",
       "       'Essen', 'Berlin', 'Darwin', 'Belfast', 'Sydney', 'Baltimore',\n",
       "       'Virginia Beach', 'Arlington', 'Louisville', 'Mesa', 'Las Vegas',\n",
       "       'Dallas', 'Washington', 'Gold Coast', 'Miami', 'Newcastle',\n",
       "       'San Antonio', 'Fresno', 'Phoenix', 'Austin', 'Stuttgart',\n",
       "       'Chicago', 'Wuppertal', 'Nashville', 'Jacksonville', 'Ballarat',\n",
       "       'Omaha', 'Oklahoma City', 'San Diego', 'Sacramento', 'Dresden',\n",
       "       'Raleigh', 'Oakland', 'Indianapolis', 'Detroit', 'Los Angeles',\n",
       "       'El Paso', 'Albuquerque'], dtype=object)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_validate_city_country=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Retail_countries = df_Retail_countries.drop(columns=['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Photon(user_agent=\"geoapiExercises\")\n",
    "\n",
    "def validate_city_country(city, country, ):\n",
    "    try:\n",
    "        # Ensure proper formatting of the query\n",
    "        query = f\"{city}, {country}\"\n",
    "        location = geolocator.geocode(query, timeout=10)\n",
    "        if location and location.address:\n",
    "            return location.address\n",
    "        else:\n",
    "            return None\n",
    "    except GeocoderTimedOut:\n",
    "        time.sleep(1)  # Wait a bit before retrying\n",
    "        return validate_city_country(city, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montevideo, Montevideo, Uruguay\n"
     ]
    }
   ],
   "source": [
    "print(validate_city_country('Montevideo','Uruguay'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique city-country pairs\n",
    "unique_city_country_pairs = df_Retail_validate_city_country[['City', 'Country']].drop_duplicates()\n",
    "unique_city_country_pairs = unique_city_country_pairs.drop_duplicates()\n",
    "# Apply the validation function to the unique city-country pairs\n",
    "unique_city_country_pairs['Validation'] = unique_city_country_pairs.apply(\n",
    "    lambda row: validate_city_country(row['City'], row['Country']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shape: (287370, 30)\n",
      "Unique city-country pairs shape: (236, 3)\n",
      "Dataframe shape after merge: (287370, 31)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataframe shape: {df_Retail_validate_city_country.shape}\")\n",
    "print(f\"Unique city-country pairs shape: {unique_city_country_pairs.shape}\")\n",
    "\n",
    "df_Retail_validate_city_country = df_Retail_validate_city_country.merge(unique_city_country_pairs, on=['City', 'Country'], how='left', suffixes=('', '_Validation'))\n",
    "\n",
    "print(f\"Dataframe shape after merge: {df_Retail_validate_city_country.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las ciudades son correctas\n"
     ]
    }
   ],
   "source": [
    "# Filtra las filas con resultados incorrectos en la validaci√≥n\n",
    "df_incorrectas = df_Retail_validate_city_country[df_Retail_validate_city_country['Validation'].isna()]\n",
    "if(df_incorrectas.empty):\n",
    "    print(\"Todas las ciudades son correctas\")\n",
    "else:\n",
    "    print(df_incorrectas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for country in pycountry.countries:\n",
    "#    print(country.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zip code es el codigo de la direccion del cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "nan_count = df_Retail_copy_unique['Zipcode'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna(subset=['Zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "nan_count_afterDrop = df_Retail_copy_unique['Zipcode'].isna().sum()\n",
    "print(nan_count_afterDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_countries_city_address=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaciones con c√≥digos postales distintos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Segment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "      <th>Total_Purchases</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Type</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Shipping_Method</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Order_Status</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Address</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Transaction_ID, Customer_ID, Name, Email, Phone, State, Zipcode, Age, Gender, Income, Customer_Segment, Date, Year, Month, Time, Total_Purchases, Amount, Total_Amount, Product_Category, Product_Brand, Product_Type, Feedback, Shipping_Method, Payment_Method, Order_Status, Ratings, products]\n",
       "Index: []"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agrupo y cuento valores unicos, es decir todos aquellos que tienen para un mismo pais, ciudad y direccion un zipcode distinto\n",
    "grouped = df_Retail_countries_city_address.groupby(['Country', 'City', 'Address'])['Zipcode'].nunique()\n",
    "\n",
    "#Filtrar los grupos con m√°s de un c√≥digo postal\n",
    "multiple_zipcodes = grouped[grouped > 1].index\n",
    "\n",
    "#Extraer las filas que corresponden a estos grupos para poder actualizar la informacion\n",
    "df_multiple_zipcodes = df_Retail_countries_city_address.set_index(['Country', 'City', 'Address']).loc[multiple_zipcodes]\n",
    "\n",
    "print(\"Combinaciones con c√≥digos postales distintos:\")\n",
    "df_multiple_zipcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_countries_zipcode=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_countries_zipcode = df_Retail_countries_zipcode.dropna(subset=['Zipcode'])\n",
    "df_Retail_countries_zipcode['Zipcode'] = df_Retail_countries_zipcode['Zipcode'].round(0)\n",
    "df_Retail_countries_zipcode['Zipcode'] = df_Retail_countries_zipcode['Zipcode'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se chequea que no hayan distintos Zipcodes para una misma direccion en una misma ciudad, estado y pais.\n",
    "Se podria verificar con una api que el Zipcode exista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique.isna().sum().sum() # number of missing cells\n",
    "round(df_Retail_copy_unique.isna().sum().sum() / df_Retail_copy_unique.size * 100, 1) # percentage of missing cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL 10% tiene datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction_ID        0\n",
       "Customer_ID         283\n",
       "Name                368\n",
       "Email               329\n",
       "Phone               343\n",
       "Address             303\n",
       "City                  0\n",
       "State                 0\n",
       "Zipcode               0\n",
       "Country             258\n",
       "Age                 167\n",
       "Gender              302\n",
       "Income              275\n",
       "Customer_Segment    205\n",
       "Date                339\n",
       "Year                340\n",
       "Month               255\n",
       "Time                329\n",
       "Total_Purchases     341\n",
       "Amount              336\n",
       "Total_Amount        332\n",
       "Product_Category    269\n",
       "Product_Brand       260\n",
       "Product_Type          0\n",
       "Feedback            174\n",
       "Shipping_Method     320\n",
       "Payment_Method      280\n",
       "Order_Status        228\n",
       "Ratings             174\n",
       "products              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por mayor comodidad, transformo todas las variables a category menos las numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_not_to_convert = ['Age', 'Zipcode','Total_Purchases', 'Amount', 'Total_Amount', 'Ratings', 'Customer_ID', 'Transaction_ID']\n",
    "all_columns = set(df_Retail_copy_unique.columns)\n",
    "\n",
    "columns_not_to_convert_set = set(columns_not_to_convert)\n",
    "columns_to_skip = list(all_columns - columns_not_to_convert_set)\n",
    "\n",
    "# Convertir las columnas restantes a tipo 'category'\n",
    "for col in columns_to_skip:\n",
    "    df_Retail_copy_unique[col] = df_Retail_copy_unique[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19., 48., 56., 22., 58., 29., 46., 25., 64., 31., 53., 32., 43.,\n",
       "       69., 49., 61., 21., 41., 38., 59., 20., 67., 50., 26., 24., 54.,\n",
       "       28., 34., 65., 40., 36., 57., 27., 35., 68., 70., 37., 30., 39.,\n",
       "       47., 60., 33., 62., 42., 18., 44., 66., 51., 63., 55., 23., 52.,\n",
       "       nan, 45.])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_copy_unique['Age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La edad esta en float, la transformo a entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna(subset=['Age'])\n",
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna(subset=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique['Age'] = df_Retail_copy_unique['Age'].astype('int')\n",
    "df_Retail_copy_unique['Year'] = df_Retail_copy_unique['Year'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiero borrar todos los valores nulos o nan pero quiero estudiar primero si me conviene borrar las filas o una columna entera, porque si los datos faltantes es tan en su mayoria en una columna puede ser mejor deshacerme de esa columna en lugar de borrar registros.\n",
    "A continuacion estudio cual es la variable que tiene la mayor cantidad de nulos o valores nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna con la mayor cantidad de NaN es: Name\n",
      "N√∫mero de NaN en esta columna: 368\n"
     ]
    }
   ],
   "source": [
    "# Calcular el n√∫mero de valores NaN por columna\n",
    "nan_counts = df_Retail_copy_unique.isna().sum()\n",
    "\n",
    "# Encontrar la columna con el mayor n√∫mero de NaN\n",
    "column_with_most_nan = nan_counts.idxmax()\n",
    "max_nan_count = nan_counts.max()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"La columna con la mayor cantidad de NaN es:\", column_with_most_nan)\n",
    "print(\"N√∫mero de NaN en esta columna:\", max_nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siendo que Name es la columna con la mayor cantidad de nulos y que esta no tiene valor estadistico para mi estudio, la elimino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique['Total_Amount'] = df_Retail_copy_unique['Total_Amount'].round(2)\n",
    "df_Retail_copy_unique['Amount'] = df_Retail_copy_unique['Amount'].round(2)\n",
    "df_Retail_copy_unique['Total_Purchases'] = df_Retail_copy_unique['Total_Purchases'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero total de filas antes de eliminar NaN: 286034\n",
      "N√∫mero total de filas despu√©s de eliminar NaN: 280322\n",
      "N√∫mero de filas eliminadas: 5712\n"
     ]
    }
   ],
   "source": [
    "# Quiero eliminar las filas que contengan NAN, pero no quiero quedarme con pocos datos por lo que cuento primero cuantas filas se borrarian\n",
    "\n",
    "total_rows_before = df_Retail_copy_unique.shape[0]\n",
    "\n",
    "# Eliminar todas las filas que contienen al menos un NaN en alguna columna\n",
    "df_Retail_copy_unique = df_Retail_copy_unique.dropna()\n",
    "\n",
    "# Contar las filas despu√©s de eliminar NaN\n",
    "total_rows_after = df_Retail_copy_unique.shape[0]\n",
    "\n",
    "# Calcular cu√°ntas filas se eliminaron\n",
    "rows_deleted = total_rows_before - total_rows_after\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"N√∫mero total de filas antes de eliminar NaN:\", total_rows_before)\n",
    "print(\"N√∫mero total de filas despu√©s de eliminar NaN:\", total_rows_after)\n",
    "print(\"N√∫mero de filas eliminadas:\", rows_deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_verificarAge=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay clientes cuya edad sea menor a 18.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay clientes con edad menor a 18\n",
    "underage_clients = (df_Retail_verificarAge['Age'] < 18).any()\n",
    "\n",
    "# Mostrar resultado\n",
    "if underage_clients:\n",
    "    print(\"Hay clientes cuya edad es menor a 18.\")\n",
    "else:\n",
    "    print(\"No hay clientes cuya edad sea menor a 18.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_verificarGender=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Female', 'Male']\n",
       "Categories (2, object): ['Female', 'Male']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_verificarGender['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_verificarIncome=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Low', 'High', 'Medium']\n",
       "Categories (3, object): ['High', 'Low', 'Medium']"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_verificarIncome['Income'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tCustomer_Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_verificarCustomer_Segment=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Premium', 'Regular', 'New']\n",
       "Categories (3, object): ['New', 'Premium', 'Regular']"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_verificarCustomer_Segment['Customer_Segment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tDate\n",
    "    Figura como mm/dd/yyyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_verificarDate=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 280322\n"
     ]
    }
   ],
   "source": [
    "num_rows_df_Retail_copy_unique = df_Retail_copy_unique.shape[0]\n",
    "print(f\"Number of rows: {num_rows_df_Retail_copy_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12/31/2023', '4/26/2023', '5/8/2023', '1/10/2024', '9/21/2023', ..., '3/31/2023', '8/23/2023', '1/24/2024', '6/7/2023', '2/1/2024']\n",
       "Length: 366\n",
       "Categories (366, object): ['1/1/2024', '1/10/2024', '1/11/2024', '1/12/2024', ..., '9/6/2023', '9/7/2023', '9/8/2023', '9/9/2023']"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_verificarDate['Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 280322\n"
     ]
    }
   ],
   "source": [
    "#Verfico que solo hay datos para el 2023 y 2024\n",
    "df_Retail_verificarDate['Date'] = pd.to_datetime(df_Retail_verificarDate['Date'], errors='coerce')\n",
    "df_Retail_verificarDate['Extracted_Year'] = df_Retail_verificarDate['Date'].dt.year\n",
    "df_Retail_verificarDate['Year_Match'] = df_Retail_verificarDate['Extracted_Year'] == df_Retail_verificarDate['Year']\n",
    "\n",
    "num_rows = df_Retail_verificarDate.shape[0]\n",
    "print(f\"Number of rows: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_verificarDate['Date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_verificarYear=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for 2023: 234125\n",
      "Number of rows for 2024: 46197\n"
     ]
    }
   ],
   "source": [
    "df_2023 = df_Retail_verificarYear[df_Retail_verificarYear['Year'] == 2023]\n",
    "df_2024 = df_Retail_verificarYear[df_Retail_verificarYear['Year'] == 2024]\n",
    "\n",
    "# Contar el n√∫mero de columnas para cada a√±o\n",
    "num_rows_2023 = df_2023.shape[0]\n",
    "num_rows_2024 = df_2024.shape[0]\n",
    "\n",
    "print(f\"Number of rows for 2023: {num_rows_2023}\")\n",
    "print(f\"Number of rows for 2024: {num_rows_2024}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay pocos datos para el 2024, realizar comparaciones entre year no es logico por lo que elimino la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_copy_unique = df_Retail_copy_unique.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tMonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Retail_verificarMonth=df_Retail_copy_unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['December', 'April', 'May', 'January', 'September', ..., 'October', 'July', 'November', 'February', 'August']\n",
       "Length: 12\n",
       "Categories (12, object): ['April', 'August', 'December', 'February', ..., 'May', 'November', 'October', 'September']"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Retail_verificarMonth['Month'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tTime\tTotal_Purchases\tAmount\tTotal_Amount\tProduct_Category\tProduct_Brand\tProduct_Type\tFeedback\tShipping_Method\tPayment_Method\tOrder_Status\tRatings\tproducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_Retail_verificarAge.drop(columns=['Phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Customer_ID'] = df_clean['Customer_ID'].astype('int')\n",
    "df_clean['Transaction_ID'] = df_clean['Transaction_ID'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_clean_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[373], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Contar las compras por a√±o\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m compras_por_a√±o \u001b[38;5;241m=\u001b[39m \u001b[43mdf_clean_unique\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Mostrar el conteo de compras por a√±o\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConteo de Compras por A√±o:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_clean_unique' is not defined"
     ]
    }
   ],
   "source": [
    "# Contar las compras por a√±o\n",
    "compras_por_a√±o = df_clean_unique['Year'].value_counts().sort_index()\n",
    "\n",
    "# Mostrar el conteo de compras por a√±o\n",
    "print(\"Conteo de Compras por A√±o:\")\n",
    "print(compras_por_a√±o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_unique = df_clean_unique.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_unique['Customer_ID'] = df_clean_unique['Customer_ID'].astype('category')\n",
    "df_clean_unique['Transaction_ID'] = df_clean_unique['Transaction_ID'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 234312 entries, 1 to 301262\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Non-Null Count   Dtype   \n",
      "---  ------            --------------   -----   \n",
      " 0   Transaction_ID    234312 non-null  category\n",
      " 1   Customer_ID       234312 non-null  category\n",
      " 2   Email             234312 non-null  category\n",
      " 3   Address           234312 non-null  category\n",
      " 4   City              234312 non-null  category\n",
      " 5   State             234312 non-null  category\n",
      " 6   Zipcode           234312 non-null  int32   \n",
      " 7   Country           234312 non-null  category\n",
      " 8   Age               234312 non-null  int32   \n",
      " 9   Gender            234312 non-null  category\n",
      " 10  Income            234312 non-null  category\n",
      " 11  Customer_Segment  234312 non-null  category\n",
      " 12  Date              234312 non-null  category\n",
      " 13  Month             234312 non-null  category\n",
      " 14  Time              234312 non-null  category\n",
      " 15  Total_Purchases   234312 non-null  float64 \n",
      " 16  Amount            234312 non-null  float64 \n",
      " 17  Total_Amount      234312 non-null  float64 \n",
      " 18  Product_Category  234312 non-null  category\n",
      " 19  Product_Brand     234312 non-null  category\n",
      " 20  Product_Type      234312 non-null  category\n",
      " 21  Feedback          234312 non-null  category\n",
      " 22  Shipping_Method   234312 non-null  category\n",
      " 23  Payment_Method    234312 non-null  category\n",
      " 24  Order_Status      234312 non-null  category\n",
      " 25  Ratings           234312 non-null  float64 \n",
      " 26  products          234312 non-null  category\n",
      "dtypes: category(21), float64(4), int32(2)\n",
      "memory usage: 43.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_clean_unique.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_Purchases</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17394.000000</td>\n",
       "      <td>17394.000000</td>\n",
       "      <td>17394.000000</td>\n",
       "      <td>17394.000000</td>\n",
       "      <td>17394.000000</td>\n",
       "      <td>17394.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49995.103254</td>\n",
       "      <td>35.419053</td>\n",
       "      <td>5.353110</td>\n",
       "      <td>256.214721</td>\n",
       "      <td>1374.169757</td>\n",
       "      <td>3.163217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29062.542596</td>\n",
       "      <td>15.086977</td>\n",
       "      <td>2.862466</td>\n",
       "      <td>141.927651</td>\n",
       "      <td>1135.256874</td>\n",
       "      <td>1.320959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>503.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>4793.950000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.066500</td>\n",
       "      <td>115.986000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24717.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>132.700000</td>\n",
       "      <td>440.347500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50380.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>256.670000</td>\n",
       "      <td>1047.015000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74637.250000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>380.570000</td>\n",
       "      <td>2036.457500</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>95656.150000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>475.838500</td>\n",
       "      <td>3694.542000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>99200.030000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>494.945600</td>\n",
       "      <td>4537.283200</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99947.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>4998.720000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Zipcode           Age  Total_Purchases        Amount  \\\n",
       "count  17394.000000  17394.000000     17394.000000  17394.000000   \n",
       "mean   49995.103254     35.419053         5.353110    256.214721   \n",
       "std    29062.542596     15.086977         2.862466    141.927651   \n",
       "min      503.000000     18.000000         1.000000     10.000000   \n",
       "5%      4793.950000     19.000000         1.000000     34.066500   \n",
       "25%    24717.500000     22.000000         3.000000    132.700000   \n",
       "50%    50380.000000     32.000000         5.000000    256.670000   \n",
       "75%    74637.250000     46.000000         8.000000    380.570000   \n",
       "95%    95656.150000     65.000000        10.000000    475.838500   \n",
       "99%    99200.030000     70.000000        10.000000    494.945600   \n",
       "max    99947.000000     70.000000        10.000000    500.000000   \n",
       "\n",
       "       Total_Amount       Ratings  \n",
       "count  17394.000000  17394.000000  \n",
       "mean    1374.169757      3.163217  \n",
       "std     1135.256874      1.320959  \n",
       "min       10.000000      1.000000  \n",
       "5%       115.986000      1.000000  \n",
       "25%      440.347500      2.000000  \n",
       "50%     1047.015000      3.000000  \n",
       "75%     2036.457500      4.000000  \n",
       "95%     3694.542000      5.000000  \n",
       "99%     4537.283200      5.000000  \n",
       "max     4998.720000      5.000000  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_unique_customer.describe(percentiles=[.05,.5,.25,.75,.95,.99])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La edad no la considero por que los customers estan repetidos, por lo que debo primero hacer una limpieza y luego estudiar estadisticamente los datos (lo hare a continuacion)\n",
    "Total_Purchases -- Es el numero de compras realizadas por el customer\n",
    "En promedio se compran 5 articulos por compra. Siendo 1 el minimo, y 10 el maximo. En esta variable no se observan valores atipicos ni la necesidad de realizar una estandarizacion. \n",
    "En promedio los articulos cuestan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las personas se repiten, si quiero estudiar estadisticamente la edad de estas, tengo que hacer un drop de duplicados de Customer_ID. Commo todos los datos son en el mismo a;o, la edad de la persona va a ser la misma para todas sus compras, por lo que no me preocupa cual registro me quedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_unique_customer=df_clean_unique.copy()\n",
    "df_clean_unique_customer = df_clean_unique_customer.drop_duplicates(subset=['Customer_ID'], keep=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
